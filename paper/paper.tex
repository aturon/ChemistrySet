\documentclass[preprint]{sigplanconf}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathpartir}

\newcommand{\ra}{\rightarrow}
\newcommand{\gives}{\vdash}
\newcommand{\proves}{\vdash}
\newcommand{\GA}{\ |\ }
\newcommand{\kw}[1]{\textsf{#1}}
\newcommand{\ty}[1]{\textrm{#1}\ }
\newcommand{\bind}{\mbox{\ \scriptsize$>\!\!>\!=$\ }}
\newcommand{\letrec}[2]{\kw{letrec}\ #1\ \kw{in}\ #2}
\newcommand{\LET}[4]{\kw{let}_{#1}\ #2 = #3\ \kw{in}\ #4}

\begin{document}

\authorinfo{}{}{}
% yikes!
\title{Reagents: expressing and composing patterns of fine-grained concurrency}
\maketitle

\begin{abstract}
blah blah
\end{abstract}

\section{Introduction}

\hspace{\stretch{1}}\emph{Programs are what happens between cache
  misses}.\footnote{Folklore; origin unknown.}

\subsection*{The problem}

Ahmdahl's law tells us that sequential bottlenecks fundamentally limit our
profit from parallelism~\cite{?}.  In practice, the effect is amplified by
another factor: interprocessor communication, often in the form of cache
coherence.  When one thread waits on another, the program pays the cost of
lost parallelism \emph{and} an extra cache miss.  The extra misses can easily
yield parallel \emph{slowdown}, more than negating the benefits of the
remaining parallelism.  

Cache, as ever, is king.

The easy answer is: avoid communication.  In other words, parallelize at a
coarse grain, giving threads large chunks of independent work.  But some work
doesn't easily factor into large chunks, or equal-size chunks.  Fine-grained
parallelism is easier to find, and easier to sprinkle throughout existing
sequential code.
%With increasing pressure to parallelize, fine-grained parallelism will only
%become more common.

Another answer is: communicate efficiently.  The past two
decades\footnote{Herlihy/Wing, Mellor-Crummey/Scott} have produced a sizable
collection of algorithms for synchronization, communication, and shared
storage which minimize the use of memory bandwidth and avoid unnecessary
waiting.  This research effort has led to industrial-strength
libraries---\texttt{java.util.concurrent} (JUC) the most prominent---offering
a wide range of concurrency primitives appropriate for fine-grained
parallelism.

Such libraries are an enormous undertaking---and one that must be repeated for
new platforms.  They tend to be conservative, implementing only those data
structures and primitives likely to fulfill common needs.  In addition, it is
generally not possible to safely combine the facilities of the library.  For
example, JUC provides queues, sets and maps, but not stacks or bags.  Its
queues come in both blocking and nonblocking forms, while its sets and maps
are nonblocking only.  Although the queues provide atomic (thread-safe)
dequeuing and sets provide atomic insertion, it is not possible to combine
these into a single atomic operation.  

In short, libraries for fine-grained concurrency are indispensable, but hard
to write, hard to extend by composition, and hard to tailor to the exact needs
of a particular user.

\subsection*{Our contribution}

We have developed a core library of \emph{composable} primitives for
fine-grained concurrency.

by no means a silver bullet.

why is this different from STM

\section{Reagents}
\label{sec:reagents}



\section{Semantics}
\label{sec:semantics}



\section{Implementation}
\label{sec:implementation}



\section{Performance}
\label{sec:performance}



\section{Related work}
\label{sec:related}



\bibliographystyle{abbrvnat}

\end{document}

# Intro notes

What do we want to accomplish?

 - motivate libraries like j.u.c
 - downsides of such libraries
   - huge research & impl effort
   - not easily extensible
   - internal structure has repeated, but unabstracted patterns
 - our contribution
   - a new way of expressing scalable algorithms that
     - doesn't lose much performance 
     - allows composition
     - is much nicer than direct programming
     - also incorporates blocking behavior

# General notes

Imposes no cache-coherence overhead on isolated data structures

Can argue that transactional-event-style liveness properties are
important if you want general way of composing fine-grained concurrent
algorithms with message-passing

To what extent do reagents encompass STM?  who are we competing with?

multiparadim, expressive, fast -- all that's great, but sales pitch
needs to be oriented around a customer with specific needs.  any
reason not to use the pitch of extensible, composable j.u.c.?

# Contributions

  - make it easier to express fine-grained concurrent algorithms,
  including blocking operations etc.  make it possible to build them
  compositionally, which already happens in the literature but is
  largely unremarked upon.

  - we capture exponential backoff, elimination backoff, and other
  such patterns once and for all

  - can use flat combining as illustration of capturing very general
  concurrency abstraction

  - smooth blend of message-passing and shared-state concurrency
  isolation for shared state, coherent communication through messages,
  uniform blocking/synchronization

  - operational semantics

  - yields completely lock-free implementation of core CML

  - generalizes join calculus implementation, allowing dissolution
  even for existing channels

  - generalizes transactions events, but with much better
  implementation

# To do

  - benchmark against STM (possibly Akka Transactors?)

  - benchmark queues, including flat combining and buckets

# Outline

2.5 Title, abstract, intro, library overview 
1.5 Semantics 
2.5 Implementation/algorithms 
1.0 Performance results
1.5 Related work
1.0 Conclusion and bib

How much time should we spend covering scalable concurrency
background?  This is perhaps tied to strategies for introducing the
library constructs: the primitives can be shown by-need for examples.
Should consult good papers like Ryan's and Jesse's for examples here.

# Semantics

Need to nail down story for overlapping state access.  In particular,
when (if ever) is an error flagged?  Unfortunately, talking about heap
unsplittability is rather more complicated than splittability.
